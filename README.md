# Vision Algorithm for Mobile Robotics 
A course taught by Professor Davide Scaramuzza (fun fact: he's a Penn alumni) at ETH Zurich. Online lecture notes and homeworks are available through the Robot Perception Group website. 

### The goal of the course 
For a robot to be autonomous, it has to perceive and understand the world around it. This course introduces you to the key computer vision algorithms used in mobile robotics, such as feature extraction, structure from motion, multiple view geometry, dense reconstruction, tracking, image retrieval, event-based vision, and visual-inertial odometry and Simultaneous Localization And Mapping (SLAM)(the algorithms behind Apple ARKit, Google Visual Positioning Service, Microsoft Hololens, Magic Leap, Oculus Quest and Oculus Insight, and the Mars Curiosity rover). Basic knowledge of algebra, geomertry, and matrix calculus are required.

### My personal goals 
This is my progress through the course, where I *only* study the lecture material. I can not attend lecture, as I am not an ETH student. My solution to the homeworks are a *python* implementation, whereas the course uses MATLAB quite extensively. 

So ETH students: Do Not Copy! :) 

# Table of Contents:
 - Lesson 1: Introduction 
    * Homework: No Homework 
 - Lesson 2: Image Formation pt. 1
    * Homework: Augmented Wire Frame Cube **Not included** 
 - Lesson 3: Image Formation pt. 2 
    * Homework: [Perspective-n-Point Problem](https://github.com/anthonyn2121/vision_algorithms/tree/master/Homework%203) 
 - Lesson 4: Filtering 
    * Homework: No Homework 
 - Lesson 5: Feature Detection 
    * Homework: Harris Corner Detection and Keypoint Tracking 
